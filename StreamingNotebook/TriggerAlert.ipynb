{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'importlib_resources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/eos/home-y/ysunthor/SWAN_projects/StreamingNotebook/notifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'importlib.resources'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-cde94aa940c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnotifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/eos/home-y/ysunthor/SWAN_projects/StreamingNotebook/notifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Try backported to PY<37 `importlib_resources`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mimportlib_resources\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'importlib_resources'"
     ]
    }
   ],
   "source": [
    "from notifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "userSchema = StructType() \\\n",
    "        .add(\"window\",StructType()\\\n",
    "             .add(\"start\",TimestampType())\\\n",
    "             .add(\"end\",TimestampType()))\\\n",
    "        .add(\"system\", StringType())\\\n",
    "        .add(\"count\", LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- system: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = spark\\\n",
    ".readStream.format(\"parquet\")\\\n",
    ".schema(userSchema)\\\n",
    ".load(\"/cms/users/carizapo/ming/groupdata_cmsweb_logs\");\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- system: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_data = spark\\\n",
    ".read.format(\"parquet\")\\\n",
    ".load(\"/cms/users/carizapo/ming/groupdata_cmsweb_logs\");\n",
    "temp_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|              window|              system|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|[2019-06-21 10:02...|/das/request?pid=...|    4|\n",
      "|[2019-06-21 09:29...|/das/request?pid=...|    3|\n",
      "|[2019-06-21 09:44...|/das/request?pid=...|    9|\n",
      "|[2019-06-21 09:44...|/das/request?pid=...|    6|\n",
      "|[2019-06-21 09:43...|/das/request?pid=...|    1|\n",
      "|[2019-06-21 10:02...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:28...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:44...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:44...|/das/request?inpu...|    1|\n",
      "|[2019-06-21 09:43...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:53...|/das/request?pid=...|    1|\n",
      "|[2019-06-21 09:23...|/das/request?pid=...|    2|\n",
      "|[2019-06-21 09:53...|/das/request?view...|    1|\n",
      "|[2019-06-21 09:23...|/das/request?view...|    1|\n",
      "|[2019-06-21 09:38...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:38...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:44...|/dqm/offline/data...|    1|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+----+-----+-----+\n",
      "|              window|system|count| avg| diff|label|\n",
      "+--------------------+------+-----+----+-----+-----+\n",
      "|[2019-06-21 09:39...|   dqm|   10|21.5|-11.5|    0|\n",
      "|[2019-06-21 09:42...|   dqm|   22|21.5|  0.5|    0|\n",
      "|[2019-06-21 09:43...|   dqm|   34|21.5| 12.5|    0|\n",
      "|[2019-06-21 09:44...|   dqm|   65|21.5| 43.5|    1|\n",
      "|[2019-06-21 09:45...|   dqm|    5|21.5|-16.5|    1|\n",
      "|[2019-06-21 09:53...|   dqm|   29|21.5|  7.5|    0|\n",
      "|[2019-06-21 09:57...|   dqm|    1|21.5|-20.5|    1|\n",
      "|[2019-06-21 09:58...|   dqm|    1|21.5|-20.5|    1|\n",
      "|[2019-06-21 09:23...|   dqm|   18|21.5| -3.5|    0|\n",
      "|[2019-06-21 09:24...|   dqm|    4|21.5|-17.5|    1|\n",
      "|[2019-06-21 09:27...|   dqm|   12|21.5| -9.5|    0|\n",
      "|[2019-06-21 09:28...|   dqm|   30|21.5|  8.5|    0|\n",
      "|[2019-06-21 09:29...|   dqm|   39|21.5| 17.5|    1|\n",
      "|[2019-06-21 09:30...|   dqm|   14|21.5| -7.5|    0|\n",
      "|[2019-06-21 09:38...|   dqm|   26|21.5|  4.5|    0|\n",
      "|[2019-06-21 09:59...|   dqm|   24|21.5|  2.5|    0|\n",
      "|[2019-06-21 10:00...|   dqm|   19|21.5| -2.5|    0|\n",
      "|[2019-06-21 10:01...|   dqm|   18|21.5| -3.5|    0|\n",
      "|[2019-06-21 10:02...|   dqm|   57|21.5| 35.5|    1|\n",
      "|[2019-06-21 10:03...|   dqm|    2|21.5|-19.5|    1|\n",
      "+--------------------+------+-----+----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "#function to calculate number of seconds from number of days\n",
    "days = lambda i: i * 86400\n",
    "\n",
    "w = Window.partitionBy('system',window(\"window.start\", \"7 days\"))\n",
    "# .orderBy(col(\"window.start\").cast('long')).rangeBetween(-days(7), 0)\n",
    "\n",
    "freq_analyze_df=temp_data.select('*', avg('count').over(w).alias('avg')).sort('system','window')\\\n",
    ".select('*', (col('count') - first('avg').over(w)).alias('diff'))\\\n",
    ".select('*', when((abs(col('diff')) > col('avg')*0.7), 1).otherwise(0).alias('label'))\n",
    "freq_analyze_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- system: string (nullable = true)\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      " |-- avg: double (nullable = true)\n",
      " |-- diff: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data=raw_data.join(freq_analyze_df, [\"system\",\"window\",\"count\"], \"inner\")\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_alert_data = raw_data.filter(\"label > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_flow = raw_data.writeStream.queryName(\"hdfs\").outputMode(\"Append\").format(\"memory\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_alert_data_flow = filter_alert_data.writeStream.queryName(\"alert\").outputMode(\"Append\").format(\"memory\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_flow.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_alert_data_flow.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_data = raw_data.withColumn('feature', concat(col('system'), col('count'))).writeStream.queryName(\"concat\").outputMode(\"Append\").format(\"memory\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_data.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7ff86a58d668>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x7ff86a7ae470>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x7ff86a7ae4e0>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data_flow.lastProgress\n",
    "# filter_alert_data_flow.lastProgress\n",
    "# raw_data_flow.processAllAvailable()\n",
    "# filter_alert_data_flow.processAllAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+----+-----+-----+\n",
      "|system|              window|count| avg| diff|label|\n",
      "+------+--------------------+-----+----+-----+-----+\n",
      "|   dqm|[2019-06-21 09:57...|    1|21.5|-20.5|    1|\n",
      "|   dqm|[2019-06-21 09:58...|    1|21.5|-20.5|    1|\n",
      "|   dqm|[2019-06-21 09:59...|   24|21.5|  2.5|    0|\n",
      "|   dqm|[2019-06-21 10:00...|   19|21.5| -2.5|    0|\n",
      "|   dqm|[2019-06-21 09:24...|    4|21.5|-17.5|    1|\n",
      "|   dqm|[2019-06-21 09:27...|   12|21.5| -9.5|    0|\n",
      "|   dqm|[2019-06-21 09:28...|   30|21.5|  8.5|    0|\n",
      "|   dqm|[2019-06-21 09:29...|   39|21.5| 17.5|    1|\n",
      "|   dqm|[2019-06-21 09:30...|   14|21.5| -7.5|    0|\n",
      "|   dqm|[2019-06-21 09:38...|   26|21.5|  4.5|    0|\n",
      "|   dqm|[2019-06-21 09:39...|   10|21.5|-11.5|    0|\n",
      "|   dqm|[2019-06-21 09:42...|   22|21.5|  0.5|    0|\n",
      "|   dqm|[2019-06-21 09:43...|   34|21.5| 12.5|    0|\n",
      "|   dqm|[2019-06-21 09:44...|   65|21.5| 43.5|    1|\n",
      "|   dqm|[2019-06-21 09:45...|    5|21.5|-16.5|    1|\n",
      "|   dqm|[2019-06-21 09:53...|   29|21.5|  7.5|    0|\n",
      "|   dqm|[2019-06-21 09:23...|   18|21.5| -3.5|    0|\n",
      "|   dqm|[2019-06-21 10:01...|   18|21.5| -3.5|    0|\n",
      "|   dqm|[2019-06-21 10:02...|   57|21.5| 35.5|    1|\n",
      "|   dqm|[2019-06-21 10:03...|    2|21.5|-19.5|    1|\n",
      "+------+--------------------+-----+----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alerts = spark.sql(\"select * from hdfs\")\n",
    "alerts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-----+------+-------+-----+\n",
      "|        system|              window|count|   avg|   diff|label|\n",
      "+--------------+--------------------+-----+------+-------+-----+\n",
      "|           dqm|[2019-06-21 09:44...|   65|  21.5|   43.5|    1|\n",
      "|           dqm|[2019-06-21 09:45...|    5|  21.5|  -16.5|    1|\n",
      "|           dqm|[2019-06-21 09:57...|    1|  21.5|  -20.5|    1|\n",
      "|           dqm|[2019-06-21 09:58...|    1|  21.5|  -20.5|    1|\n",
      "|           dqm|[2019-06-21 09:24...|    4|  21.5|  -17.5|    1|\n",
      "|           dqm|[2019-06-21 09:29...|   39|  21.5|   17.5|    1|\n",
      "|           dqm|[2019-06-21 10:02...|   57|  21.5|   35.5|    1|\n",
      "|           dqm|[2019-06-21 10:03...|    2|  21.5|  -19.5|    1|\n",
      "|           dbs|[2019-06-21 09:24...|   14|1428.2|-1414.2|    1|\n",
      "|           dbs|[2019-06-21 09:39...|  152|1428.2|-1276.2|    1|\n",
      "|           dbs|[2019-06-21 09:42...|  279|1428.2|-1149.2|    1|\n",
      "|           dbs|[2019-06-21 09:45...|  263|1428.2|-1165.2|    1|\n",
      "|           dbs|[2019-06-21 09:53...| 2993|1428.2| 1564.8|    1|\n",
      "|           dbs|[2019-06-21 09:57...|   63|1428.2|-1365.2|    1|\n",
      "|           dbs|[2019-06-21 09:58...|  362|1428.2|-1066.2|    1|\n",
      "|           dbs|[2019-06-21 09:59...| 4514|1428.2| 3085.8|    1|\n",
      "|           dbs|[2019-06-21 10:00...|  339|1428.2|-1089.2|    1|\n",
      "|           dbs|[2019-06-21 10:02...| 6735|1428.2| 5306.8|    1|\n",
      "|           dbs|[2019-06-21 10:03...|  273|1428.2|-1155.2|    1|\n",
      "|/server-status|[2019-06-21 09:24...|    1|  18.0|  -17.0|    1|\n",
      "+--------------+--------------------+-----+------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alerts = spark.sql(\"select * from alert\")\n",
    "alerts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_data_week_flow=raw_data.writeStream \\\n",
    ".outputMode(\"append\")\\\n",
    ".format(\"parquet\")\\\n",
    " .option(\"path\", \"/cms/users/carizapo/ming/moving_avg_cmsweb_logs\") \\\n",
    " .option(\"checkpointLocation\", \"/cms/users/carizapo/ming/checkpoint_moving_avg_cmsweb_logs\") \\\n",
    " .outputMode(\"append\") \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfs_data_week_flow.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.1"
    },
    {
     "name": "spark.jars",
     "value": "/eos/home-y/ysunthor/SWAN_projects/StreamingNotebook"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "userSchema = StructType() \\\n",
    "        .add(\"window\",StructType()\\\n",
    "             .add(\"start\",TimestampType())\\\n",
    "             .add(\"end\",TimestampType()))\\\n",
    "        .add(\"system\", StringType())\\\n",
    "        .add(\"count\", LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- system: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = spark\\\n",
    ".readStream.format(\"parquet\")\\\n",
    ".schema(userSchema)\\\n",
    ".load(\"/cms/users/carizapo/ming/groupdata_cmsweb_logs\");\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- system: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_data = spark\\\n",
    ".read.format(\"parquet\")\\\n",
    ".load(\"/cms/users/carizapo/ming/groupdata_cmsweb_logs\");\n",
    "temp_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|              window|              system|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|[2019-06-21 10:02...|/das/request?pid=...|    4|\n",
      "|[2019-06-21 09:29...|/das/request?pid=...|    3|\n",
      "|[2019-06-21 09:44...|/das/request?pid=...|    9|\n",
      "|[2019-06-21 09:44...|/das/request?pid=...|    6|\n",
      "|[2019-06-21 09:43...|/das/request?pid=...|    1|\n",
      "|[2019-06-21 10:02...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:28...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:44...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:44...|/das/request?inpu...|    1|\n",
      "|[2019-06-21 09:43...|/das/request?inst...|    1|\n",
      "|[2019-06-21 09:53...|/das/request?pid=...|    1|\n",
      "|[2019-06-21 09:23...|/das/request?pid=...|    2|\n",
      "|[2019-06-21 09:53...|/das/request?view...|    1|\n",
      "|[2019-06-21 09:23...|/das/request?view...|    1|\n",
      "|[2019-06-21 09:38...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:38...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|\n",
      "|[2019-06-21 09:44...|/dqm/offline/data...|    1|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+----+-----+-----+\n",
      "|              window|system|count| avg| diff|label|\n",
      "+--------------------+------+-----+----+-----+-----+\n",
      "|[2019-06-21 09:39...|   dqm|   10|21.5|-11.5|    0|\n",
      "|[2019-06-21 09:42...|   dqm|   22|21.5|  0.5|    0|\n",
      "|[2019-06-21 09:43...|   dqm|   34|21.5| 12.5|    0|\n",
      "|[2019-06-21 09:44...|   dqm|   65|21.5| 43.5|    1|\n",
      "|[2019-06-21 09:45...|   dqm|    5|21.5|-16.5|    1|\n",
      "|[2019-06-21 09:53...|   dqm|   29|21.5|  7.5|    0|\n",
      "|[2019-06-21 09:57...|   dqm|    1|21.5|-20.5|    1|\n",
      "|[2019-06-21 09:58...|   dqm|    1|21.5|-20.5|    1|\n",
      "|[2019-06-21 09:23...|   dqm|   18|21.5| -3.5|    0|\n",
      "|[2019-06-21 09:24...|   dqm|    4|21.5|-17.5|    1|\n",
      "|[2019-06-21 09:27...|   dqm|   12|21.5| -9.5|    0|\n",
      "|[2019-06-21 09:28...|   dqm|   30|21.5|  8.5|    0|\n",
      "|[2019-06-21 09:29...|   dqm|   39|21.5| 17.5|    1|\n",
      "|[2019-06-21 09:30...|   dqm|   14|21.5| -7.5|    0|\n",
      "|[2019-06-21 09:38...|   dqm|   26|21.5|  4.5|    0|\n",
      "|[2019-06-21 09:59...|   dqm|   24|21.5|  2.5|    0|\n",
      "|[2019-06-21 10:00...|   dqm|   19|21.5| -2.5|    0|\n",
      "|[2019-06-21 10:01...|   dqm|   18|21.5| -3.5|    0|\n",
      "|[2019-06-21 10:02...|   dqm|   57|21.5| 35.5|    1|\n",
      "|[2019-06-21 10:03...|   dqm|    2|21.5|-19.5|    1|\n",
      "+--------------------+------+-----+----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "#function to calculate number of seconds from number of days\n",
    "days = lambda i: i * 86400\n",
    "\n",
    "w = Window.partitionBy('system',window(\"window.start\", \"7 days\"))\n",
    "# .orderBy(col(\"window.start\").cast('long')).rangeBetween(-days(7), 0)\n",
    "\n",
    "freq_analyze_df=temp_data.select('*', avg('count').over(w).alias('avg')).sort('system','window')\\\n",
    ".select('*', (col('count') - first('avg').over(w)).alias('diff'))\\\n",
    ".select('*', when((abs(col('diff')) > col('avg')*0.7), 1).otherwise(0).alias('label'))\n",
    "freq_analyze_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- system: string (nullable = true)\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      " |-- avg: double (nullable = true)\n",
      " |-- diff: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data=raw_data.join(freq_analyze_df, [\"system\",\"window\",\"count\"], \"inner\")\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_flow = raw_data.writeStream.queryName(\"hdfs\").outputMode(\"Append\").format(\"memory\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_flow.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_data = raw_data.withColumn('feature', concat(col('system'), col('count'))).writeStream.queryName(\"concat\").outputMode(\"Append\").format(\"memory\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_data.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7ff86a73cd30>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fb161127-f1f7-4b1c-b1fe-ecfa1ad686ce',\n",
       " 'runId': '9e0f330c-6ea9-4ed7-a3a5-df1eb33d7989',\n",
       " 'name': 'hdfs',\n",
       " 'timestamp': '2019-06-26T11:28:16.875Z',\n",
       " 'batchId': 1,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'getOffset': 492, 'triggerExecution': 492},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'FileStreamSource[hdfs://analytix/cms/users/carizapo/ming/groupdata_cmsweb_logs]',\n",
       "   'startOffset': {'logOffset': 0},\n",
       "   'endOffset': {'logOffset': 0},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'MemorySink'}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_flow.lastProgress\n",
    "# raw_data_flow.processAllAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+----+-----+-----+\n",
      "|system|              window|count| avg| diff|label|\n",
      "+------+--------------------+-----+----+-----+-----+\n",
      "|   dqm|[2019-06-21 09:57...|    1|21.5|-20.5|    1|\n",
      "|   dqm|[2019-06-21 09:58...|    1|21.5|-20.5|    1|\n",
      "|   dqm|[2019-06-21 09:59...|   24|21.5|  2.5|    0|\n",
      "|   dqm|[2019-06-21 10:00...|   19|21.5| -2.5|    0|\n",
      "|   dqm|[2019-06-21 09:24...|    4|21.5|-17.5|    1|\n",
      "|   dqm|[2019-06-21 09:27...|   12|21.5| -9.5|    0|\n",
      "|   dqm|[2019-06-21 09:28...|   30|21.5|  8.5|    0|\n",
      "|   dqm|[2019-06-21 09:29...|   39|21.5| 17.5|    1|\n",
      "|   dqm|[2019-06-21 09:30...|   14|21.5| -7.5|    0|\n",
      "|   dqm|[2019-06-21 09:38...|   26|21.5|  4.5|    0|\n",
      "|   dqm|[2019-06-21 09:39...|   10|21.5|-11.5|    0|\n",
      "|   dqm|[2019-06-21 09:42...|   22|21.5|  0.5|    0|\n",
      "|   dqm|[2019-06-21 09:43...|   34|21.5| 12.5|    0|\n",
      "|   dqm|[2019-06-21 09:44...|   65|21.5| 43.5|    1|\n",
      "|   dqm|[2019-06-21 09:45...|    5|21.5|-16.5|    1|\n",
      "|   dqm|[2019-06-21 09:53...|   29|21.5|  7.5|    0|\n",
      "|   dqm|[2019-06-21 09:23...|   18|21.5| -3.5|    0|\n",
      "|   dqm|[2019-06-21 10:01...|   18|21.5| -3.5|    0|\n",
      "|   dqm|[2019-06-21 10:02...|   57|21.5| 35.5|    1|\n",
      "|   dqm|[2019-06-21 10:03...|    2|21.5|-19.5|    1|\n",
      "+------+--------------------+-----+----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alerts = spark.sql(\"select * from hdfs\")\n",
    "alerts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+\n",
      "|              window|              system|count|             feature|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|[2019-06-21 10:02...|/das/request?pid=...|    4|/das/request?pid=...|\n",
      "|[2019-06-21 09:29...|/das/request?pid=...|    3|/das/request?pid=...|\n",
      "|[2019-06-21 09:44...|/das/request?pid=...|    9|/das/request?pid=...|\n",
      "|[2019-06-21 09:44...|/das/request?pid=...|    6|/das/request?pid=...|\n",
      "|[2019-06-21 09:43...|/das/request?pid=...|    1|/das/request?pid=...|\n",
      "|[2019-06-21 10:02...|/das/request?inst...|    1|/das/request?inst...|\n",
      "|[2019-06-21 09:28...|/das/request?inst...|    1|/das/request?inst...|\n",
      "|[2019-06-21 09:44...|/das/request?inst...|    1|/das/request?inst...|\n",
      "|[2019-06-21 09:44...|/das/request?inpu...|    1|/das/request?inpu...|\n",
      "|[2019-06-21 09:43...|/das/request?inst...|    1|/das/request?inst...|\n",
      "|[2019-06-21 09:53...|/das/request?pid=...|    1|/das/request?pid=...|\n",
      "|[2019-06-21 09:23...|/das/request?pid=...|    2|/das/request?pid=...|\n",
      "|[2019-06-21 09:53...|/das/request?view...|    1|/das/request?view...|\n",
      "|[2019-06-21 09:23...|/das/request?view...|    1|/das/request?view...|\n",
      "|[2019-06-21 09:38...|/dqm/offline/data...|    1|/dqm/offline/data...|\n",
      "|[2019-06-21 09:38...|/dqm/offline/data...|    1|/dqm/offline/data...|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|/dqm/offline/data...|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|/dqm/offline/data...|\n",
      "|[2019-06-21 09:42...|/dqm/offline/data...|    1|/dqm/offline/data...|\n",
      "|[2019-06-21 09:44...|/dqm/offline/data...|    1|/dqm/offline/data...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alerts = spark.sql(\"select * from concat\")\n",
    "alerts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.1"
    },
    {
     "name": "spark.jars",
     "value": "/eos/home-y/ysunthor/SWAN_projects/StreamingNotebook"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user pykafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykafka import KafkaClient\n",
    "client = KafkaClient(hosts=\"188.185.79.229:9092\")\n",
    "topic = client.topics['email_alert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = topic.get_simple_consumer()\n",
    "for message in consumer:\n",
    "    print(message.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://central.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.3.1/spark-streaming-kafka-0-8-assembly_2.11-2.3.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import TopicAndPartition\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc =SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 5) #change frequency of getting data\n",
    "ssc.checkpoint(\"_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafkaStream =KafkaUtils.createDirectStream(ssc, [\"email_alert\"],\n",
    "                                           {\n",
    "                                               \"metadata.broker.list\":\"188.185.79.229:9092\",\n",
    "                                               \"auto.offset.reset\":\"smallest\"\n",
    "                                           }\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = kafkaStream.map(lambda v: json.loads(v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "emails_dstream = parsed.map(lambda email: [email['subject'],1])\\\n",
    "                        .reduceByKeyAndWindow(lambda x,y: x+y, 10, 5)\n",
    "# emails_dstream.pprint()\n",
    "# benchmark=emails_dstream.map(lambda x:[x[0],x[1],x[1]>30])\n",
    "benchmark=emails_dstream.map(lambda x: sendingAlert)\n",
    "benchmark.pprint()\n",
    "ssc.start()\n",
    "ssc.awaitTerminationOrTimeout(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendingAlert():\n",
    "    return \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed.map().reduceByKeyAndWindow(,, windowDuration=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_counts_sorted_dstream = subject_counts.transform(\\\n",
    "#   (lambda foo:foo\\\n",
    "#    .sortBy(lambda x:( -x[1]))))\n",
    "# top_five_subjects = subject_counts_sorted_dstream.transform\\\n",
    "#   (lambda rdd:sc.parallelize(rdd.take(5)))\n",
    "# top_five_subjects.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://central.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8_2.11/2.0.0-preview/spark-streaming-kafka-0-8_2.11-2.0.0-preview.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars",
     "value": "/eos/home-y/ysunthor/SWAN_projects/test"
    },
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-streaming-kafka-0-8-assembly_2.11:2.3.1"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
